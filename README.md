# ğŸŒŒ QuietEdge: Symbolic AI Assistant (Offline, Local-First)

**QuietEdge** is a modular, local-first AI assistant system powered by Ollama. It runs entirely offline with no cloud dependencies, offering symbolic, multi-persona interaction through a Gradio web UI and a streaming terminal interface.

- ğŸ”’ **Privacy-first**: All interactions stay on your machine
- ğŸ”§ **Modular tools**: Note-taking, summarization, search (extensible)
- ğŸ§  **Multiple personas**: Define styles, memory scope, tools per agent
- ğŸŒ€ **Symbolic protocol**: Context-aware routing through the MCP layer
- âœ¨ **Simple and elegant**: Quiet by design, with an intuitive interface

---

## ğŸ“ Project Structure

```
ollama_starter/
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ mcp.py                  # Context coordination layer
â”‚   â”œâ”€â”€ memory.py               # Long-term and persona memory
â”‚   â”œâ”€â”€ ollama_assistant.py     # Ollama local model interface
â”‚   â”œâ”€â”€ personas.py             # Define and switch AI personas
â”‚   â””â”€â”€ tools/                  # Modular symbolic tools
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ stream_terminal_chat.py # Terminal-based streaming chat
â”‚   â”œâ”€â”€ launch_web_ui.py        # Gradio UI launcher
â”‚   â””â”€â”€ clean_structure.sh      # Project cleanup automation
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ interface.py            # Gradio logic
â”‚   â”œâ”€â”€ ui.py                   # Stream handling and formatting
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Setup Instructions

### 1. Install Dependencies

```bash
# Create and activate your environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install Ollama if not installed
curl -fsSL https://ollama.com/install.sh | sh
```

---

### 2. Start Ollama (locally)

```bash
ollama serve
ollama run mistral  # Or your preferred model (e.g., llama3)
```

---

## ğŸš€ Usage

### ğŸŒ Launch Web UI (Gradio)

```bash
python scripts/launch_web_ui.py
```

Features:
- Persona switching
- Markdown + streaming output
- Interactive tools (note-taking, summarization, search)
- Tag-based prompt parsing (`@note`, `@summarize`, etc.)

---

### ğŸ’» Stream Terminal Chat

```bash
python scripts/stream_terminal_chat.py
```

Use markdown, tags, or CLI-friendly prompts like:

```text
::note summarize todayâ€™s meeting
::search how to build local LLM assistant
```

---

## ğŸ§© Features

- âœ… Symbolic tool system with `@tags` and command triggers
- âœ… Multi-persona support (memory, tone, tool access)
- âœ… Streaming support (both UI and terminal)
- âœ… Modular MCP for intelligent input routing
- âœ… Extensible memory backend (JSON, SQLite optional)
- âœ… Minimal dependencies, low RAM usage

---

## ğŸ¤ Contributing

Pull requests welcome!

```bash
# Fork and clone
git clone https://github.com/yourname/ollama_starter.git
cd ollama_starter

# Make your changes on a new branch
git checkout -b feature/my-improvement
```

To submit:
1. Follow clean Python structure
2. Keep symbolic clarity and naming consistency
3. Test `main/` logic before UI calls it

---

## ğŸ” Philosophy

QuietEdge is designed for thinkers, artists, and builders who want powerful AI tools without noise, cloud, or distraction. Each persona reflects a facet of intelligence. The system respects autonomy, creativity, and clarity.

---

## ğŸ“œ License

MIT â€” free to use, remix, build.

---

Made with ğŸ› ï¸ in a quiet room, far from the cloud.
